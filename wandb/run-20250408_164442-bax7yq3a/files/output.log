Start training...
wandb: WARNING Fatal error while uploading data. Some run data will not be synced, but it will still be written to disk. Use `wandb sync` at the end of the run to try uploading.
2.39 s ± 49.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
Results are saved in:  results\train_511fd2c4070ac018bc404c9c7435878f
===================================================================================================================
Layer (type:depth-idx)                   Input Shape               Output Shape              Param #
===================================================================================================================
Transformer                              [128, 82]                 [128, 82, 16]             --
├─Embedding: 1-1                         [128, 82]                 [128, 82, 64]             1,024
├─ModuleList: 1-2                        --                        --                        --
│    └─TFBlock: 2-1                      [128, 82, 64]             [128, 82, 64]             --
│    │    └─LayerNorm: 3-1               [128, 82, 64]             [128, 82, 64]             128
│    │    └─MultiHeadAttention: 3-2      [128, 82, 64]             [128, 82, 64]             16,384
│    │    └─Dropout: 3-3                 [128, 82, 64]             [128, 82, 64]             --
│    │    └─LayerNorm: 3-4               [128, 82, 64]             [128, 82, 64]             128
│    │    └─Sequential: 3-5              [128, 82, 64]             [128, 82, 64]             16,576
│    │    └─Dropout: 3-6                 [128, 82, 64]             [128, 82, 64]             --
│    └─TFBlock: 2-2                      [128, 82, 64]             [128, 82, 64]             --
│    │    └─LayerNorm: 3-7               [128, 82, 64]             [128, 82, 64]             128
│    │    └─MultiHeadAttention: 3-8      [128, 82, 64]             [128, 82, 64]             16,384
│    │    └─Dropout: 3-9                 [128, 82, 64]             [128, 82, 64]             --
│    │    └─LayerNorm: 3-10              [128, 82, 64]             [128, 82, 64]             128
│    │    └─Sequential: 3-11             [128, 82, 64]             [128, 82, 64]             16,576
│    │    └─Dropout: 3-12                [128, 82, 64]             [128, 82, 64]             --
│    └─TFBlock: 2-3                      [128, 82, 64]             [128, 82, 64]             --
│    │    └─LayerNorm: 3-13              [128, 82, 64]             [128, 82, 64]             128
│    │    └─MultiHeadAttention: 3-14     [128, 82, 64]             [128, 82, 64]             16,384
│    │    └─Dropout: 3-15                [128, 82, 64]             [128, 82, 64]             --
│    │    └─LayerNorm: 3-16              [128, 82, 64]             [128, 82, 64]             128
│    │    └─Sequential: 3-17             [128, 82, 64]             [128, 82, 64]             16,576
│    │    └─Dropout: 3-18                [128, 82, 64]             [128, 82, 64]             --
├─Linear: 1-3                            [128, 82, 64]             [128, 82, 16]             1,040
===================================================================================================================
Total params: 101,712
Trainable params: 101,712
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 13.02
===================================================================================================================
Input size (MB): 0.08
Forward/backward pass size (MB): 151.81
Params size (MB): 0.41
Estimated Total Size (MB): 152.31
===================================================================================================================
Initialized model, optimizer, and train state
Initialized data samplers
