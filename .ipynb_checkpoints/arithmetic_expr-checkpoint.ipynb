{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8b9db2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from models.base_models import Transformer\n",
    "from arithmetic_sampler import ArithmeticSampler\n",
    "from config import get_config\n",
    "from train import train\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8604f9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config()\n",
    "sampler = ArithmeticSampler(config.task.max_variables)\n",
    "model = Transformer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2a38e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are saved in:  results/train_e791069c5cae4ac9d47c461d4f718897\n",
      "===================================================================================================================\n",
      "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
      "===================================================================================================================\n",
      "Transformer                              [256, 82]                 [256, 82, 16]             --\n",
      "├─Embedding: 1-1                         [256, 82]                 [256, 82, 64]             1,024\n",
      "├─ModuleList: 1-2                        --                        --                        --\n",
      "│    └─TFBlock: 2-1                      [256, 82, 64]             [256, 82, 64]             --\n",
      "│    │    └─Identity: 3-1                [256, 82, 64]             [256, 82, 64]             --\n",
      "│    │    └─MultiHeadAttention: 3-2      [256, 82, 64]             [256, 82, 64]             16,384\n",
      "│    └─TFBlock: 2-2                      [256, 82, 64]             [256, 82, 64]             --\n",
      "│    │    └─Identity: 3-3                [256, 82, 64]             [256, 82, 64]             --\n",
      "│    │    └─MultiHeadAttention: 3-4      [256, 82, 64]             [256, 82, 64]             16,384\n",
      "│    │    └─Identity: 3-5                [256, 82, 64]             [256, 82, 64]             --\n",
      "│    │    └─Sequential: 3-6              [256, 82, 64]             [256, 82, 64]             16,576\n",
      "├─Linear: 1-3                            [256, 82, 64]             [256, 82, 16]             1,040\n",
      "===================================================================================================================\n",
      "Total params: 51,408\n",
      "Trainable params: 51,408\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 13.16\n",
      "===================================================================================================================\n",
      "Input size (MB): 0.17\n",
      "Forward/backward pass size (MB): 131.66\n",
      "Params size (MB): 0.21\n",
      "Estimated Total Size (MB): 132.04\n",
      "===================================================================================================================\n",
      "Initialized model, optimizer, and train state\n",
      "Initialized data samplers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhyan84\u001b[0m (\u001b[33mhyan84-university-of-wisconsin-madison\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/hyan/Downloads/LLM/Reasoning/Reasoning/wandb/run-20250407_231310-knb73vne</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hyan84-university-of-wisconsin-madison/Reasoning/runs/knb73vne' target=\"_blank\">train_e791069c5cae4ac9d47c461d4f718897</a></strong> to <a href='https://wandb.ai/hyan84-university-of-wisconsin-madison/Reasoning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hyan84-university-of-wisconsin-madison/Reasoning' target=\"_blank\">https://wandb.ai/hyan84-university-of-wisconsin-madison/Reasoning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hyan84-university-of-wisconsin-madison/Reasoning/runs/knb73vne' target=\"_blank\">https://wandb.ai/hyan84-university-of-wisconsin-madison/Reasoning/runs/knb73vne</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "742b8660000042a193df2f6d4078cdd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "train(model, sampler, config, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7d7cbb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16 s ± 3.52 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "sampler.generate(2**17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dcfa841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, mask = sampler.generate(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9c746e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['                        ((4+4)+(0-5))+(6-(1-((7-2)-7)))=(8+(0-5))+(6-(1-((7-2)-7)))']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler.decode(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f000cd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_transformer(model, batch, mask, tokenizer=None, temperature=1.0, top_k=None):\n",
    "    \"\"\"\n",
    "    model: Transformer with output logits of shape (B, T, vocab_size)\n",
    "    input_ids: LongTensor of shape (1, T) — starting token sequence\n",
    "    k: how many tokens to sample\n",
    "    tokenizer: (optional) for decoding results\n",
    "    \"\"\"\n",
    "    k = mask.sum().item()\n",
    "    model.eval()\n",
    "    seq_len = batch.shape[1]\n",
    "    batch = F.pad(batch, pad=(k, 0), value=15)\n",
    "    print(batch.shape)\n",
    "    generated = batch[:,:seq_len].clone()\n",
    "\n",
    "    for t in range(k):\n",
    "        # Get model output for current sequence\n",
    "        with torch.no_grad():\n",
    "            output, _ = model(generated[:,t:seq_len+t])  # logits: (1, T, vocab_size)\n",
    "\n",
    "        logits = output[:, -1, :]  # get logits for the last token\n",
    "\n",
    "        # Apply temperature\n",
    "        logits = logits / temperature\n",
    "\n",
    "        # (Optional) Top-k filtering\n",
    "        if top_k is not None:\n",
    "            values, indices = torch.topk(logits, top_k)\n",
    "            mask = logits < values[:, [-1]]\n",
    "            logits[mask] = float('-inf')\n",
    "\n",
    "        probs = F.softmax(logits, dim=-1)  # shape (1, vocab_size)\n",
    "        next_token = torch.multinomial(probs, num_samples=1)  # shape (1, 1)\n",
    "\n",
    "        # Append sampled token to sequence\n",
    "        generated = torch.cat((generated, next_token), dim=1)\n",
    "\n",
    "    if tokenizer:\n",
    "        return tokenizer.decode(generated[0], skip_special_tokens=True)\n",
    "    return generated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8e6a3552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 110])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['                                                   ((4+4)+(0-5))+(6-(1-((7-2)-7)))=(1+1)))))))))))))1-62-6))))']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler.decode(sample_from_transformer(model, batch, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "efdec591",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = batch[:, 1:]\n",
    "target_mask = mask[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "073a0aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 82])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4eb8bc53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 82])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b0c3fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
